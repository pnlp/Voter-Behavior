{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing for Campaign Speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Notebook [Mini Time Series Modeling](Mini_Time_posing.ipynb)\n",
    "### Next Notebook [Conclusions in Outline Notebook](Outline_Project.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section analysis the election speechs of the presidential nominees from 2004 through 2016. The first section processes the speeches into a usable foramt and removes special characters and the candidates name from the speeches.\n",
    "- [Preprocessing](#section1)\n",
    "\n",
    "The second section predicts the party of the candidate that gaves the speech based of which words and the frequency in which they they appear. As well as the sentimentand and polarity analysis of each of the speeches.\n",
    "- [Modeling - Predicting Party](#section2)\n",
    "- [Modeling - Predicting Election](#section3)\n",
    "\n",
    "The third and forth sections show the most freequent words by party, and then by election.\n",
    "- [Most Frequent Words by Party](#section3)\n",
    "- [Most Frequent Words by Election](#section4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/Penelope/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob, Word\n",
    "import timeit\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics as m\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in needed files\n",
    "df_kerry = pd.read_csv('./csv_files/speech_kerry')\n",
    "df_bush = pd.read_csv('./csv_files/speech_bush')\n",
    "df_obama = pd.read_csv('./csv_files/speech_obama')\n",
    "df_mccain = pd.read_csv('./csv_files/speech_mccain')\n",
    "df_obama_2 = pd.read_csv('./csv_files/speech_obama_2')\n",
    "df_romney = pd.read_csv('./csv_files/speech_romney')\n",
    "df_clinton = pd.read_csv('./csv_files/speech_clinton')\n",
    "df_trump = pd.read_csv('./csv_files/speech_trump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add features to indicate election year and party of candidate\n",
    "df_kerry['party'] = 1\n",
    "df_kerry['year'] = 2004\n",
    "df_bush['party'] = 0\n",
    "df_bush['year'] = 2004\n",
    "df_obama['party'] = 1\n",
    "df_obama['year'] = 2008\n",
    "df_mccain['party'] = 0\n",
    "df_mccain['year'] = 2008\n",
    "df_obama_2['party'] = 1\n",
    "df_obama_2['year'] = 2012\n",
    "df_romney['party'] = 0\n",
    "df_romney['year'] = 2012\n",
    "df_clinton['party'] = 1\n",
    "df_clinton['year'] = 2016\n",
    "df_trump['party'] = 0\n",
    "df_trump['year'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the speeches of all the candidates\n",
    "\n",
    "df = pd.concat([df_kerry, df_bush, df_obama, df_mccain, df_obama_2, df_romney, \n",
    "                df_clinton, df_trump], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reindex()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40039840637450197"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = 402 / 1004\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all special characters and names of candidates so predicting party is base on only content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['speech'] = df['speech'].apply(lambda x: x.lower().replace(\"\\\\'\", \"'\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"\"\"'\"\"\", \"\"\"\"\"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace('''\"''', ''''''))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\".\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\",\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\";\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\":\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"going\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"kerry\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"john\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"bush\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"george\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"obama\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"barack\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"mccain\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"romney\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"mitt\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"clinton\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"hillary\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"trump\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"donald\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns that show the subjectivity and polarity score of each speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 46.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "subjectivity = []\n",
    "polarity = []\n",
    "for i in range(0, len(df.speech)):\n",
    "    sub = TextBlob(df.speech[i]).sentiment.subjectivity\n",
    "    subjectivity.append(sub)\n",
    "    \n",
    "    pol = TextBlob(df.speech[i]).sentiment.polarity\n",
    "    polarity.append(pol)\n",
    "\n",
    "df['subjectivity'] = subjectivity\n",
    "df['polarity'] = polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the stem of each word so that words with the same root registed in the model as the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1min 30s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "sp = []\n",
    "\n",
    "for speech in df.speech:\n",
    "    stem_list = []\n",
    "    speech_new = []\n",
    "    speech = speech.split()\n",
    "    for word in speech:\n",
    "        w = Word(word)\n",
    "        stem = w.stem()\n",
    "        stem_list.append(stem)\n",
    "    speech_new = ' '.join(stem_list)\n",
    "    sp.append(speech_new)\n",
    "\n",
    "# define a new column that holds the speeches with words in stem form. So that the speech columns remains intact.\n",
    "df['stems'] = sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "# Modeling - Predicting Party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Logistic Regression](#subsection1)\n",
    "- [Random Forest Classifier](#subsection2)\n",
    "- [Neural Network](#subsection3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subsection1'></a>\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score 0.97150997151\n",
      "Cross Validated Accuracy Train Score 0.913098591549\n",
      "Test Accuracy Score 0.966887417219\n",
      "Cross Validated Accuracy Test Score 0.877540983607\n",
      "[[105   7]\n",
      " [  3 187]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.95       112\n",
      "          1       0.96      0.98      0.97       190\n",
      "\n",
      "avg / total       0.97      0.97      0.97       302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the predictive features and the predicted columns\n",
    "\n",
    "X = df[['stems', 'subjectivity', 'polarity']]\n",
    "y = df.party\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "# initialize vectoizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# fit and transform training data\n",
    "tfidf.fit(X_train.stems)\n",
    "X_train_tf = tfidf.transform(X_train.stems)\n",
    "\n",
    "# turn into data frame and concat\n",
    "X_train_tf = pd.DataFrame(X_train_tf.todense())\n",
    "train_sub_pol = X_train[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "X_train_tf = pd.concat([X_train_tf, train_sub_pol], axis=1)\n",
    "\n",
    "\n",
    "# test data\n",
    "X_test_tf = tfidf.transform(X_test.stems)\n",
    "X_test_tf = pd.DataFrame(X_test_tf.todense())\n",
    "test_sub_pol = X_test[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "X_test_tf = pd.concat([X_test_tf, test_sub_pol], axis=1)\n",
    "\n",
    "\n",
    "# initialize and fit model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_tf, y_train)\n",
    "train_predictions = logreg.predict(X_train_tf)\n",
    "\n",
    "print('Train Accuracy Score', logreg.score(X_train_tf, y_train))\n",
    "print('Cross Validated Accuracy Train Score', cross_val_score(logreg, X_train_tf, y_train, cv=5).mean())\n",
    "\n",
    "\n",
    "test_predictions = logreg.predict(X_test_tf)\n",
    "print('Test Accuracy Score', logreg.score(X_test_tf, y_test))\n",
    "print('Cross Validated Accuracy Test Score', cross_val_score(logreg, X_test_tf, y_test, cv=5).mean())\n",
    "print(m.confusion_matrix(y_test, test_predictions))\n",
    "print(m.classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cross Validated Accuracy Score on the test data is 0.87\n",
    "\n",
    "This model is is 87% accurate when predicting the party on new data. \n",
    "The confusion martix shows that the model predicted that 3 speeches as Democratic but were actually Republican. \n",
    "It incorrectly predicted 7 speeches were Republican, that were actually Democratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subsection2'></a>\n",
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses Random Forest Classifier, an ensemble method with a base of Decision Tree. This model doesn't preform as well as the Logistic Regression so it is not included in the final report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score 1.0\n",
      "Cross Validated Accuracy Train Score 0.874688128773\n",
      "Accuracy Score 0.907284768212\n",
      "Cross Validated Accuracy Test Score 0.847595628415\n",
      "[[ 92  20]\n",
      " [  8 182]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.82      0.87       112\n",
      "          1       0.90      0.96      0.93       190\n",
      "\n",
      "avg / total       0.91      0.91      0.91       302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the predictive features and the predicted columns\n",
    "\n",
    "X = df[['stems', 'subjectivity', 'polarity']]\n",
    "y = df.party\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X_train.stems)\n",
    "X_train_tf = tfidf.transform(X_train.stems)\n",
    "\n",
    "\n",
    "X_train_tf = pd.DataFrame(X_train_tf.todense())\n",
    "\n",
    "\n",
    "train_sub_pol = X_train[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "X_train = pd.concat([X_train_tf, train_sub_pol], axis=1)\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=36, n_estimators=22)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "train_predictions = rfc.predict(X_train)\n",
    "\n",
    "print('Train Accuracy Score', rfc.score(X_train, y_train))\n",
    "print('Cross Validated Accuracy Train Score', cross_val_score(rfc, X_train, y_train, cv=5).mean())\n",
    "\n",
    "# vectorize and concat test data\n",
    "X_test_tf = tfidf.transform(X_test.stems)\n",
    "X_test_tf = pd.DataFrame(X_test_tf.todense())\n",
    "\n",
    "test_sub_pol = X_test[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "X_test = pd.concat([X_test_tf, test_sub_pol], axis=1)\n",
    "\n",
    "\n",
    "test_predictions = rfc.predict(X_test)\n",
    "print('Accuracy Score', rfc.score(X_test, y_test))\n",
    "print('Cross Validated Accuracy Test Score', cross_val_score(rfc, X_test, y_test, cv=5).mean())\n",
    "print(m.confusion_matrix(y_test, test_predictions))\n",
    "print(m.classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Random Forest model actually produces a better accuracy score on the training data. But the cross validated accuracy on the test data is much better in the Logistic Regression. Indicating that this model is better at predicting the party of new data. \n",
    "\n",
    "The point of predicting the party of the speeches is to show that there are fundamental differences in the words choosen by the nominees each party has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch on Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was a GridSearch on used with the Random Forest Classifier to optimize the hyper paramers. This increased the Cross Validated Score on the Test data, but not enough to challenge the results from Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X_train.speech)\n",
    "X_train_tf = tfidf.transform(X_train.speech)\n",
    "\n",
    "\n",
    "X_train_tf = pd.DataFrame(X_train_tf.todense())\n",
    "\n",
    "\n",
    "train_sub_pol = X_train[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "X_train_tf = pd.concat([X_train_tf, train_sub_pol], axis=1)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators':range(5, 26),\n",
    "    'max_depth':range(5, 40),  \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(rfc, params, verbose=2, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train_tf, y_train)\n",
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier - Most Indicative Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This section results a dataframe of the most words that were the most indicative of party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>abl</td>\n",
       "      <td>0.006285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>actual</td>\n",
       "      <td>0.005074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>afford</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>enemi</td>\n",
       "      <td>0.007446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>enterpris</td>\n",
       "      <td>0.007738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>freedom</td>\n",
       "      <td>0.006764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719</th>\n",
       "      <td>insur</td>\n",
       "      <td>0.006130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855</th>\n",
       "      <td>invest</td>\n",
       "      <td>0.007737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13503</th>\n",
       "      <td>just</td>\n",
       "      <td>0.006970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14191</th>\n",
       "      <td>liberti</td>\n",
       "      <td>0.005887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16109</th>\n",
       "      <td>natur</td>\n",
       "      <td>0.006686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16116</th>\n",
       "      <td>navi</td>\n",
       "      <td>0.007587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17913</th>\n",
       "      <td>percent</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19366</th>\n",
       "      <td>radic</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22352</th>\n",
       "      <td>start</td>\n",
       "      <td>0.009195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23814</th>\n",
       "      <td>think</td>\n",
       "      <td>0.009032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24159</th>\n",
       "      <td>togeth</td>\n",
       "      <td>0.007572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_names  feature_importances\n",
       "973             abl             0.006285\n",
       "1167         actual             0.005074\n",
       "1293         afford             0.012500\n",
       "8445          enemi             0.007446\n",
       "8531      enterpris             0.007738\n",
       "9968        freedom             0.006764\n",
       "12719         insur             0.006130\n",
       "12855        invest             0.007737\n",
       "13503          just             0.006970\n",
       "14191       liberti             0.005887\n",
       "16109         natur             0.006686\n",
       "16116          navi             0.007587\n",
       "17913       percent             0.005408\n",
       "19366         radic             0.005434\n",
       "22352         start             0.009195\n",
       "23814         think             0.009032\n",
       "24159        togeth             0.007572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names() \n",
    "feature_names.append('subjectivity') \n",
    "feature_names.append('polarity')\n",
    "importance = list(rfc.feature_importances_)\n",
    "results = pd.DataFrame()\n",
    "results['feature_names'] = feature_names\n",
    "results['feature_importances'] = importance\n",
    "\n",
    "results = results[results['feature_importances'] > .005]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subsection3'></a>\n",
    "## Neural Network - Keras with TensorFlow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the predictive features and the predicted columns\n",
    "\n",
    "X = df[['stems', 'subjectivity', 'polarity']]\n",
    "y = df.party\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "# initialize vectorizer \n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X_train.stems)\n",
    "\n",
    "# fit and transform training data with vectoizer\n",
    "X_train_tf = tfidf.transform(X_train.stems)\n",
    "X_train_tf = pd.DataFrame(X_train_tf.todense())\n",
    "\n",
    "# transform test data with vectorizer\n",
    "X_test_tf = tfidf.transform(X_test.stems)\n",
    "X_test_tf = pd.DataFrame(X_test_tf.todense())\n",
    "\n",
    "# concat the vecotried matrixes \n",
    "train_sub_pol = X_train[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "test_sub_pol = X_test[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "\n",
    "X_train = pd.concat([X_train_tf, train_sub_pol], axis=1)\n",
    "X_test = pd.concat([X_test_tf, test_sub_pol], axis=1)\n",
    "\n",
    "# standardize data\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 702 samples, validate on 302 samples\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 17s 25ms/step - loss: 0.7613 - acc: 0.7179 - val_loss: 0.1908 - val_acc: 0.9106\n",
      "Epoch 2/10\n",
      "576/702 [=======================>......] - ETA: 2s - loss: 0.4728 - acc: 0.9340"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(500, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict_classes(X_train)\n",
    "\n",
    "print(m.confusion_matrix(y_train, pred_train))\n",
    "print(m.classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict_classes(X_test)\n",
    "\n",
    "print(m.confusion_matrix(y_test, pred_test))\n",
    "print(m.classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='section3'></a>\n",
    "# Modeling Two - Predicting Election Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.year.apply(lambda x: 1 if x == 2004 else (2 if x == 2008 else(3 if x == 2012 else 4)))\n",
    "\n",
    "print(len(y))\n",
    "print(y.value_counts())\n",
    "baseline = 402/1004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the predictive features and the predicted columns\n",
    "X = df[['stems', 'subjectivity', 'polarity']]\n",
    "y = df.year.apply(lambda x: 1 if x == 2004 else (2 if x == 2008 else(3 if x == 2012 else 4)))\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "# initialize vectorizer \n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X_train.stems)\n",
    "\n",
    "# fit and transform training data with vectoizer\n",
    "X_train_tf = tfidf.transform(X_train.stems)\n",
    "X_train_tf = pd.DataFrame(X_train_tf.todense())\n",
    "\n",
    "# transform test data with vectorizer\n",
    "X_test_tf = tfidf.transform(X_test.stems)\n",
    "X_test_tf = pd.DataFrame(X_test_tf.todense())\n",
    "\n",
    "# concat the vecotried matrixes \n",
    "train_sub_pol = X_train[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "test_sub_pol = X_test[['subjectivity', 'polarity']].reset_index().drop(['index'], axis=1)\n",
    "\n",
    "X_train = pd.concat([X_train_tf, train_sub_pol], axis=1)\n",
    "X_test = pd.concat([X_test_tf, test_sub_pol], axis=1)\n",
    "\n",
    "# standardize the data \n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(500, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=20)\n",
    "\n",
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = (pred_test == pred_test.max(axis=1, keepdims=True)).astype(float)\n",
    "\n",
    "pred_test = pred_test.argmax(1)\n",
    "y_test = y_test.argmax(1)\n",
    "\n",
    "print('Confusion Matrix \\n', pd.crosstab(y_test, pred_test, rownames=['Actual'], colnames=['Predicted'], \n",
    "                                         margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy Score is 97% compared to a baseline of 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "# Most Frequent Words in Speeches by Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"applause\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"laughter\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"laughr\", \"\"))\n",
    "\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"america\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"american\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"think\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"this\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"thats\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"make\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"know\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"want\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"im \", \" \"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"weve\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"got\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"just\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"like\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"need\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"said\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"cheers\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"te \", \" \"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"ns \", \" \"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"dont\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"senator\", \"\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"president\", \"\"))\n",
    "\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"unemployed\", \"unemployment\")\n",
    "                                  .replace(\"unemployments\", \"unemployment\").replace(\"jobs\", \"unemployment\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"school\", \"education\").replace(\"teachers\", \"education\")\n",
    "                                  .replace(\"teachers\", \"education\").replace(\"student\", \"education\")\n",
    "                                  .replace(\"students\", \"education\").replace(\"literacy\", \"education\")\n",
    "                                  .replace(\"literate\", \"education\").replace(\"college\", \"education\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"wealth\", \"income\").replace(\"class\", \"income\")\n",
    "                                  .replace(\"billionaire\", \"income\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"afordable\", \"equality\").replace(\"comprehensive\", \"equality\")\n",
    "                                  .replace(\"comprehensive\", \"equality\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"immigrant\", \"immigration\").replace(\"migrant\", \"immigration\")\n",
    "                                  .replace(\"migration\", \"immigration\").replace(\"mexico\", \"immigration\")\n",
    "                                  .replace(\"wall\", \"immigration\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"troops\", \"war\").replace(\"iraq\", \"war\")\n",
    "                                  .replace(\"iran\", \"war\").replace(\"fight\", \"war\").replace(\"security\", \"war\")\n",
    "                                  .replace(\"military\", \"war\")\n",
    "                                  .replace(\"enemies\", \"war\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"oil\", \"energy\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"children\", \"families\"))\n",
    "df['speech'] = df['speech'].apply(lambda x: x.replace(\"taxation\", \"tax\")).replace(\"job\", \"unemployment\")\\\n",
    "                                .replace(\"worker\", \"unemployment\").replace(\"workers\", \"unemployment\")\\\n",
    "                                .replace(\"work\", \"unemployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df[df.party == 1]\n",
    "# print('Democratic Average Subjectivity', X.subjectivity.mean())\n",
    "# print('Democratic Average Polarity', X.polarity.mean())\n",
    "X = X.speech\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X)\n",
    "\n",
    "count = pd.DataFrame(tfidf.transform(X).todense(),columns=tfidf.get_feature_names())\n",
    "count = count/100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.tick_params(axis='x', which='both', bottom='off', labelbottom='off')\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "count.sum().sort_values(ascending=True)[-20:].plot(kind='barh', color='cornflowerblue')\n",
    "plt.title('Word Frequency Democrats', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.party == 0]\n",
    "# print('Republican Average Subjectivity', X.subjectivity.mean())\n",
    "# print('Republican Average Polarity', X.polarity.mean())\n",
    "X = X.speech\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X)\n",
    "\n",
    "count = pd.DataFrame(tfidf.transform(X).todense(),columns=tfidf.get_feature_names())\n",
    "count = count/100\n",
    "  \n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.tick_params(axis='x', which='both', bottom='off', labelbottom='off')    \n",
    "plt.yticks(fontsize=15)\n",
    "    \n",
    "count.sum().sort_values(ascending=True)[-20:].plot(kind='barh', color='firebrick')\n",
    "plt.title('Word Frequency Republicans', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "# Most Frequent Words by Election\n",
    "\n",
    "- [2004](#subsection5)\n",
    "- [2008](#subsection6)\n",
    "- [2012](#subsection7)\n",
    "- [2016](#subsection8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subsection5'></a>\n",
    "## 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.year == 2004]\n",
    "# print('2004 Average Democratic Subjectivity', X[X.party == 1].subjectivity.mean())\n",
    "# print('2004 Average Republican Subjectivity', X[X.party == 0].subjectivity.mean())\n",
    "# print('2004 Average Democratic Polarity', X[X.party == 1].polarity.mean())\n",
    "# print('2004 Average Republican Polarity', X[X.party == 0].polarity.mean())\n",
    "X = X.speech\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X)\n",
    "\n",
    "count = pd.DataFrame(tfidf.transform(X).todense(),columns=tfidf.get_feature_names())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.tick_params(axis='x', which='both', bottom='off', labelbottom='off')\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "count.sum().sort_values(ascending=True)[-15:].plot(kind='barh', color='cadetblue')\n",
    "plt.title('Word Frequency 2004 Election', fontsize=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subsection6'></a>\n",
    "## 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.year == 2008]\n",
    "# print('2008 Average Democratic Subjectivity', X[X.party == 1].subjectivity.mean())\n",
    "# print('2008 Average Republican Subjectivity', X[X.party == 0].subjectivity.mean())\n",
    "# print('2008 Average Democratic Polarity', X[X.party == 1].polarity.mean())\n",
    "# print('2008 Average Republican Polarity', X[X.party == 0].polarity.mean())\n",
    "X = X.speech\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X)\n",
    "\n",
    "count = pd.DataFrame(tfidf.transform(X).todense(),columns=tfidf.get_feature_names())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.tick_params(axis='x', which='both', bottom='off', labelbottom='off')\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "count.sum().sort_values(ascending=True)[-15:].plot(kind='barh', color='cadetblue')\n",
    "plt.title('Word Frequency 2008 Election', fontsize=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subsection7'></a>\n",
    "## 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.year == 2012]\n",
    "# print('2012 Average Democratic Subjectivity', X[X.party == 1].subjectivity.mean())\n",
    "# print('2012 Average Republican Subjectivity', X[X.party == 0].subjectivity.mean())\n",
    "# print('2012 Average Democratic Polarity', X[X.party == 1].polarity.mean())\n",
    "# print('2012 Average Republican Polarity', X[X.party == 0].polarity.mean())\n",
    "X = X.speech\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X)\n",
    "\n",
    "count = pd.DataFrame(tfidf.transform(X).todense(),columns=tfidf.get_feature_names())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.tick_params(axis='x', which='both', bottom='off', labelbottom='off')\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "count.sum().sort_values(ascending=True)[-15:].plot(kind='barh', color='cadetblue')\n",
    "plt.title('Word Frequency 2012 Election', fontsize=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subsection8'></a>\n",
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.year == 2016]\n",
    "# print('2016 Average Democratic Subjectivity', X[X.party == 1].subjectivity.mean())\n",
    "# print('2016 Average Republican Subjectivity', X[X.party == 0].subjectivity.mean())\n",
    "# print('2016 Average Democratic Polarity', X[X.party == 1].polarity.mean())\n",
    "# print('2016 Average Republican Polarity', X[X.party == 0].polarity.mean())\n",
    "X = X.speech\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X)\n",
    "\n",
    "count = pd.DataFrame(tfidf.transform(X).todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.tick_params(axis='x', which='both', bottom='off', labelbottom='off')\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "count.sum().sort_values(ascending=True)[-15:].plot(kind='barh', color='cadetblue')\n",
    "plt.title('Word Frequency 2016 Election', fontsize=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Notebook [Conclusions in Outline Notebook](Outline_Project.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
