{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape for Election Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape for Speech ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each speech has a specific id in it's url, but there is no order to which canidate's speeches get which id. So to start the scrape for the speeches, a list of the IDs are scraped from the candidates page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_2004_kerry = 'http://www.presidency.ucsb.edu/2004_election_speeches.php?candidate=67&campaign=2004KERRY'\n",
    "\n",
    "url_2008_obama = 'http://www.presidency.ucsb.edu/2008_election_speeches.php?candidate=44&campaign=2008OBAMA&doctype=5000'\n",
    "url_2008_mccain = 'http://www.presidency.ucsb.edu/2008_election_speeches.php?candidate=68&campaign=2008MCCAIN&doctype=5000'\n",
    "\n",
    "url_2012_obama = 'http://www.presidency.ucsb.edu/2012_election_speeches.php?candidate=44&doctype=1157'\n",
    "url_2012_romney = 'http://www.presidency.ucsb.edu/2012_election_speeches.php?candidate=79&campaign=2012ROMNEY&doctype=5000'\n",
    "\n",
    "url_2016_clinton = 'http://www.presidency.ucsb.edu/2016_election_speeches.php?candidate=70&campaign=2016CLINTON&doctype=5000'\n",
    "url_2016_trump = 'http://www.presidency.ucsb.edu/2016_election_speeches.php?candidate=45&campaign=2016TRUMP&doctype=5000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url_2004_kerry)\n",
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pids_kerry = []\n",
    "rows = soup.find_all('tr')\n",
    "for i in range(49, 138):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:34])\n",
    "    pids_kerry.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(url_2008_obama)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "pids_obama = []\n",
    "rows = soup.find_all('tr')\n",
    "for i in range(49, 276):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:34])\n",
    "    pids_obama.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(url_2008_mccain)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "pids_mccain = []\n",
    "rows = soup.find_all('tr')\n",
    "for i in range(49, 224):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:34])\n",
    "    pids_mccain.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(url_2012_obama)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "pids_obama_2 = []\n",
    "rows = soup.find_all('tr')\n",
    "for i in range(49, 89):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:34])\n",
    "    pids_obama_2.append(pid)\n",
    "    \n",
    "for i in range(89, 153):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:35])\n",
    "    pids_obama_2.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(url_2012_romney)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "pids_romney = []\n",
    "rows = soup.find_all('tr')\n",
    "for i in range(49, 67):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:34])\n",
    "    pids_romney.append(pid)\n",
    "\n",
    "for i in range(67, 150):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:35])\n",
    "    pids_romney.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(url_2016_clinton)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "pids_clinton = []\n",
    "rows = soup.find_all('tr')\n",
    "for i in range(49, 156):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:34])\n",
    "    pids_clinton.append(pid)\n",
    "\n",
    "for i in range(156, 245):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:35])\n",
    "    pids_clinton.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(url_2016_trump)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "pids_trump = []\n",
    "rows = soup.find_all('tr')\n",
    "for i in range(49, 123):\n",
    "    row = rows[i].find('a')\n",
    "    row = str(row)\n",
    "    pid = int(row[29:35])\n",
    "    pids_trump.append(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape for Speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the IDs to go troug each speech, a dataframe from each catidates speeches is created. Each row is an entire speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_speech = 'http://www.presidency.ucsb.edu/ws/index.php?pid={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_kerry = pd.DataFrame()\n",
    "\n",
    "speech = []\n",
    "for i in pids_kerry:\n",
    "    res = requests.get(url_speech .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find('span', {\"class\" : \"displaytext\"})\n",
    "    speech.append(rows.text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "df_kerry['speech'] = speech\n",
    "df_kerry['year'] = 2004 \n",
    "df_kerry['candidate'] = 'kerry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_kerry['speech'] = speech\n",
    "df_kerry['year'] = 2004 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_obama = pd.DataFrame()\n",
    "\n",
    "speech = []\n",
    "for i in pids_obama:\n",
    "    res = requests.get(url_speech .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find('span', {\"class\" : \"displaytext\"})\n",
    "    speech.append(rows.text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "df_obama['speech'] = speech\n",
    "df_obama['year'] = 2008 \n",
    "df_obama['candidate'] = 'obama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_obama['speech'] = speech\n",
    "df_obama['year'] = 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mccain = pd.DataFrame()\n",
    "\n",
    "speech = []\n",
    "for i in pids_mccain:\n",
    "    res = requests.get(url_speech .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find('span', {\"class\" : \"displaytext\"})\n",
    "    speech.append(rows.text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "df_mccain['speech'] = speech\n",
    "df_mccain['year'] = 2008 \n",
    "df_mccain['candidate'] = 'mccain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mccain['speech'] = speech\n",
    "df_mccain['year'] = 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_obama_2 = pd.DataFrame()\n",
    "\n",
    "speech = []\n",
    "for i in pids_obama_2:\n",
    "    res = requests.get(url_speech .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find('span', {\"class\" : \"displaytext\"})\n",
    "    speech.append(rows.text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "df_obama_2['speech'] = speech\n",
    "df_obama_2['year'] = 2008 \n",
    "df_obama_2['candidate'] = 'obama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_obama_2['speech'] = speech\n",
    "df_obama_2['year'] = 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_romney = pd.DataFrame()\n",
    "\n",
    "speech = []\n",
    "for i in pids_romney:\n",
    "    res = requests.get(url_speech .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find('span', {\"class\" : \"displaytext\"})\n",
    "    speech.append(rows.text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "df_romney['speech'] = speech\n",
    "df_romney['year'] = 2008 \n",
    "df_romney['candidate'] = 'romney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-d94797c894b2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-d94797c894b2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df_romney['year'] = 2008 v\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_romney['speech'] = speech\n",
    "df_romney['year'] = 2008 v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clinton = pd.DataFrame()\n",
    "\n",
    "speech = []\n",
    "for i in pids_clinton:\n",
    "    res = requests.get(url_speech .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find('span', {\"class\" : \"displaytext\"})\n",
    "    speech.append(rows.text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "df_clinton['speech'] = speech\n",
    "df_clinton['year'] = 2008 \n",
    "df_clinton['candidate'] = 'clinton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clinton['speech'] = speech\n",
    "df_clinton['year'] = 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trump = pd.DataFrame()\n",
    "\n",
    "speech = []\n",
    "for i in pids_trump:\n",
    "    res = requests.get(url_speech .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find('span', {\"class\" : \"displaytext\"})\n",
    "    speech.append(rows.text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "df_trump['speech'] = speech\n",
    "df_trump['year'] = 2008 \n",
    "df_trump['candidate'] = 'trump'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trump['speech'] = speech\n",
    "df_trump['year'] = 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_kerry.shape, df_obama.shape, df_mccain.shape, df_obama_2.shape, df_ronmey.shape, df_clinton.shape, df_trump.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bush's 2004 election speeches were not stored on this site, so they come from a different website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bush_dates = ['bush_nov3', 'bush_oct29', 'bush_oct27', 'bush_oct26', 'bush_oct23', \n",
    "              'bush_oct22', 'bush_oct21', 'bush_oct20', 'bush_oct19', 'bush_oct18', \n",
    "              'bush_oct15', 'bush_oct14', 'bush_oct11', 'bush_oct6', 'bush_oct2', \n",
    "              'bush_sept23', 'bush_sept21', '09.23.04', '09.21.04', 'bush_sept17', \n",
    "              'bush_sept15', 'bush_sept14', 'bush_sept13', 'bush_sept13b', 'bush_sept10', \n",
    "              'bush_sept9', 'bush_sept6', 'bush_sept2', 'bush_aug28', 'bush_aug26', \n",
    "              'bush_aug18', 'bush_aug16', 'bush_aug6', 'bush_aug4', 'bush_aug3', \n",
    "              'bush_july30', 'bush_july30.1', 'bush_july23', 'bush_july21', 'bush_july20', \n",
    "              'bush_july14', 'bush_july9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_bush = 'http://www.presidentialrhetoric.com/campaign/speeches/{}.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bush = pd.DataFrame()\n",
    "speech = []\n",
    "\n",
    "for i in bush_dates:\n",
    "    res = requests.get(url_bush .format(i))\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    rows = soup.find_all('p', {\"align\" : \"left\", \"class\":\"style2\"})\n",
    "    time.sleep(2)\n",
    "    sub_speeches = []\n",
    "    for x in rows:\n",
    "        sub_speeches.append(x.text)\n",
    "\n",
    "    sub = []\n",
    "    for x in sub_speeches:\n",
    "        x = x.replace('\\r                      ', ' ')\n",
    "        x = x.replace('\\r', ' ')\n",
    "        x = x.replace('                    ', ' ')\n",
    "        sub.append(x)\n",
    "        \n",
    "    \n",
    "\n",
    "    try:\n",
    "        speech.append(''.join(sub))\n",
    "    except:\n",
    "        print('list empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bush['candidate'] = 'bush'\n",
    "df_bush['year'] = 2008 \n",
    "df_bush['speech'] = speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bush['candidate'] = 'bush'\n",
    "df_bush['year'] = 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bush.drop([16, 17, 18, 27], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bush.to_csv('./csv_files/speech_bush', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_kerry.to_csv('./csv_files/speech_kerry', index=False)\n",
    "df_bush.to_csv('./csv_files/speech_bush', index=False)\n",
    "\n",
    "df_obama.to_csv('./csv_files/speech_obama', index=False)\n",
    "df_mccain.to_csv('./csv_files/speech_mccain', index=False)\n",
    "\n",
    "df_obama_2.to_csv('./csv_files/speech_obama_2', index=False)\n",
    "df_romney.to_csv('./csv_files/speech_romney', index=False)\n",
    "\n",
    "df_clinton.to_csv('./csv_files/speech_clinton', index=False)\n",
    "df_trump.to_csv('./csv_files/speech_trump', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
